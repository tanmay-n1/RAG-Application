{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"llama3.2:latest\"\n",
    "MODEL = \"mistral:latest\"\n",
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"mydocs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "def load_documents():\n",
    "    print(\"Loading documents\")\n",
    "    loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def split_text(documents: list[Document]):\n",
    "    print(\"Splitting text\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "    document = chunks[10]\n",
    "    print(document.page_content)\n",
    "    print(document.metadata)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "    print(\"Saving to Chroma\")\n",
    "    # Clear out the database first.\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "    # Create a new DB from the documents.\n",
    "    db = Chroma.from_documents(\n",
    "        chunks, OllamaEmbeddings(model=\"nomic-embed-text\"), persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    db.persist()\n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_store():\n",
    "    documents = load_documents()\n",
    "    chunks = split_text(documents)\n",
    "    save_to_chroma(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents\n",
      "Splitting text\n",
      "Split 23 documents into 136 chunks.\n",
      " Obvious: Use visual cues, like placing a book on your pillow to read before bed \n",
      " Attractive: Pair an enjoyable activity with a necessary one (e.g., listening to podcasts \n",
      "while exercising) \n",
      " Easy: Reduce steps needed to start a habit (e.g., sleeping in workout clothes) \n",
      " Satisfying: Celebrate small wins and track progress visually\n",
      "{'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-02-23T11:10:24-05:00', 'author': '', 'moddate': '2025-02-23T11:10:24-05:00', 'title': 'Microsoft Word - Atomic Habits', 'source': 'mydocs\\\\Atomic Habits.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2', 'start_index': 797}\n",
      "Saving to Chroma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_8940\\4200232466.py:14: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  chunks, OllamaEmbeddings(model=\"nomic-embed-text\"), persist_directory=CHROMA_PATH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 136 chunks to chroma.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_8940\\4200232466.py:16: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "generate_data_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_26780\\3395372694.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model= MODEL)\n",
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_26780\\3395372694.py:7: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_26780\\3395372694.py:8: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find matching results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_26780\\3395372694.py:11: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 5, 'page_label': '6', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 0, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='\"The statement of a problem guides the selection of the relevant precedent, and the \\nprecedent in turn frames the problem and thereby biases the solution. \" \\nFraming eƯects. The way information is presented (framed) can signiﬁcantly inﬂuence \\ndecision-making, even when the underlying facts remain the same. This eƯect'), -280.8838222180336), (Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 5, 'page_label': '6', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 243, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='decision-making, even when the underlying facts remain the same. This eƯect \\ndemonstrates that our preferences are not as stable as we might think and are often \\nconstructed in the moment based on context. \\nTypes of framing. Common framing eƯects include: \\n\\uf0b7 Gain vs. loss framing (e.g., \"90% survival rate\" vs. \"10% mortality rate\")'), -281.33725526458403), (Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 5, 'page_label': '6', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 500, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='\\uf0b7 Gain vs. loss framing (e.g., \"90% survival rate\" vs. \"10% mortality rate\") \\n\\uf0b7 Positive vs. negative framing (e.g., \"95% fat-free\" vs. \"5% fat\") \\n\\uf0b7 Temporal framing (e.g., short-term vs. long-term consequences) \\nImplications of framing: \\n\\uf0b7 Marketing and advertising strategies \\n\\uf0b7 Public policy communication \\n\\uf0b7 Medical decision-making \\n\\uf0b7 Financial choices'), -304.50841265782606), (Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 4, 'page_label': '5', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 1189, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='\\uf0b7 Emotional attachment \\n\\uf0b7 Sense of ownership \\n\\uf0b7 Reference points and expectations \\nUnderstanding these biases can help individuals and organizations make more rational \\ndecisions, especially in negotiations, investments, and product pricing strategies. \\n8. Framing: How Presentation AƯects Decision-Making'), -330.0726328394288)]\n",
      "  results = db.similarity_search_with_relevance_scores(query_text, k=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 5, 'page_label': '6', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 0, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='\"The statement of a problem guides the selection of the relevant precedent, and the \\nprecedent in turn frames the problem and thereby biases the solution. \" \\nFraming eƯects. The way information is presented (framed) can signiﬁcantly inﬂuence \\ndecision-making, even when the underlying facts remain the same. This eƯect'),\n",
       "  -280.8838222180336),\n",
       " (Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 5, 'page_label': '6', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 243, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='decision-making, even when the underlying facts remain the same. This eƯect \\ndemonstrates that our preferences are not as stable as we might think and are often \\nconstructed in the moment based on context. \\nTypes of framing. Common framing eƯects include: \\n\\uf0b7 Gain vs. loss framing (e.g., \"90% survival rate\" vs. \"10% mortality rate\")'),\n",
       "  -281.33725526458403),\n",
       " (Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 5, 'page_label': '6', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 500, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='\\uf0b7 Gain vs. loss framing (e.g., \"90% survival rate\" vs. \"10% mortality rate\") \\n\\uf0b7 Positive vs. negative framing (e.g., \"95% fat-free\" vs. \"5% fat\") \\n\\uf0b7 Temporal framing (e.g., short-term vs. long-term consequences) \\nImplications of framing: \\n\\uf0b7 Marketing and advertising strategies \\n\\uf0b7 Public policy communication \\n\\uf0b7 Medical decision-making \\n\\uf0b7 Financial choices'),\n",
       "  -304.50841265782606),\n",
       " (Document(metadata={'author': '', 'creationdate': '2025-02-23T11:11:14-05:00', 'creator': 'PyPDF', 'moddate': '2025-02-23T11:11:14-05:00', 'page': 4, 'page_label': '5', 'producer': 'Microsoft: Print To PDF', 'source': 'mydocs\\\\Thinking fast and slow.pdf', 'start_index': 1189, 'title': 'Microsoft Word - Thinking fast and slow', 'total_pages': 8}, page_content='\\uf0b7 Emotional attachment \\n\\uf0b7 Sense of ownership \\n\\uf0b7 Reference points and expectations \\nUnderstanding these biases can help individuals and organizations make more rational \\ndecisions, especially in negotiations, investments, and product pricing strategies. \\n8. Framing: How Presentation AƯects Decision-Making'),\n",
       "  -330.0726328394288)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "model = Ollama(model= MODEL)\n",
    "\n",
    "query_text = \"What is framing?\"\n",
    "\n",
    "# Prepare the DB.\n",
    "embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "# Search the DB.\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=4)\n",
    "if len(results) == 0 or results[0][1] < 0.7:\n",
    "    print(f\"Unable to find matching results.\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't \n",
      "answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based on the context below. If you can't \n",
      "answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: \"The statement of a problem guides the selection of the relevant precedent, and the \n",
      "precedent in turn frames the problem and thereby biases the solution. \" \n",
      "Framing eƯects. The way information is presented (framed) can signiﬁcantly inﬂuence \n",
      "decision-making, even when the underlying facts remain the same. This eƯect\n",
      "\n",
      "---\n",
      "\n",
      "decision-making, even when the underlying facts remain the same. This eƯect \n",
      "demonstrates that our preferences are not as stable as we might think and are often \n",
      "constructed in the moment based on context. \n",
      "Types of framing. Common framing eƯects include: \n",
      " Gain vs. loss framing (e.g., \"90% survival rate\" vs. \"10% mortality rate\")\n",
      "\n",
      "---\n",
      "\n",
      " Gain vs. loss framing (e.g., \"90% survival rate\" vs. \"10% mortality rate\") \n",
      " Positive vs. negative framing (e.g., \"95% fat-free\" vs. \"5% fat\") \n",
      " Temporal framing (e.g., short-term vs. long-term consequences) \n",
      "Implications of framing: \n",
      " Marketing and advertising strategies \n",
      " Public policy communication \n",
      " Medical decision-making \n",
      " Financial choices\n",
      "\n",
      "---\n",
      "\n",
      " Emotional attachment \n",
      " Sense of ownership \n",
      " Reference points and expectations \n",
      "Understanding these biases can help individuals and organizations make more rational \n",
      "decisions, especially in negotiations, investments, and product pricing strategies. \n",
      "8. Framing: How Presentation AƯects Decision-Making\n",
      "\n",
      "Question: What is framing?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_26780\\993480867.py:8: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_text = model.predict(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Framing refers to the way information is presented, which can significantly influence decision-making even when the underlying facts remain the same. Common types of framing include gain vs. loss framing, positive vs. negative framing, and temporal framing. Understanding these biases can help individuals and organizations make more rational decisions in various areas such as negotiations, investments, product pricing strategies, marketing and advertising, public policy communication, medical decision-making, and financial choices. It also impacts emotional attachment, sense of ownership, reference points, and expectations.\n",
      "Sources: ['mydocs\\\\Thinking fast and slow.pdf', 'mydocs\\\\Thinking fast and slow.pdf', 'mydocs\\\\Thinking fast and slow.pdf', 'mydocs\\\\Thinking fast and slow.pdf']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "print(prompt)\n",
    "\n",
    "response_text = model.predict(prompt)\n",
    "\n",
    "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(template)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    # print(prompt)\n",
    "\n",
    "    model = Ollama(model=\"mistral\")\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    # sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    # formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    # print(formatted_response)\n",
    "\n",
    "    sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    print(formatted_response)\n",
    "    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  To form good habits, follow these steps:\n",
      "\n",
      "1. Identify a current habit you already do each day and stack your new behavior on top using the technique called Habit Stacking.\n",
      "2. Increase friction for bad habits (e.g., unplug the TV after each use).\n",
      "3. Decrease friction for good habits (e.g., prepare gym clothes the night before).\n",
      "4. Make habits obvious, attractive, easy, and satisfying by following the Four Laws of Behavior Change:\n",
      "   a. Make it obvious: Increase visibility of cues that trigger desired habits.\n",
      "   b. Make it attractive: Associate habits with positive emotions or rewards.\n",
      "5. Create chains of habits by anchoring new habits to existing ones, and chaining small habits together using the natural momentum that comes from one behavior leading into the next.\n",
      "6. Focus on mastering the art of showing up and making habits automatic by spending the first two minutes on your desired habit to lower the barrier to entry and increase the chances of long-term success.\n",
      "7. Change your environment if needed, as habits are often tied to specific contexts or locations. If you're struggling with a habit at home, try performing it in a different location like a coffee shop or library.\n",
      "Sources: ['mydocs\\\\Atomic Habits.pdf', 'mydocs\\\\Atomic Habits.pdf', 'mydocs\\\\Atomic Habits.pdf', 'mydocs\\\\Atomic Habits.pdf', 'mydocs\\\\Atomic Habits.pdf']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" To form good habits, follow these steps:\\n\\n1. Identify a current habit you already do each day and stack your new behavior on top using the technique called Habit Stacking.\\n2. Increase friction for bad habits (e.g., unplug the TV after each use).\\n3. Decrease friction for good habits (e.g., prepare gym clothes the night before).\\n4. Make habits obvious, attractive, easy, and satisfying by following the Four Laws of Behavior Change:\\n   a. Make it obvious: Increase visibility of cues that trigger desired habits.\\n   b. Make it attractive: Associate habits with positive emotions or rewards.\\n5. Create chains of habits by anchoring new habits to existing ones, and chaining small habits together using the natural momentum that comes from one behavior leading into the next.\\n6. Focus on mastering the art of showing up and making habits automatic by spending the first two minutes on your desired habit to lower the barrier to entry and increase the chances of long-term success.\\n7. Change your environment if needed, as habits are often tied to specific contexts or locations. If you're struggling with a habit at home, try performing it in a different location like a coffee shop or library.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_rag(\"How do i form good habits?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm your chatbot. Ask me anything.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rephrase_query_with_ollama' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFeel free to ask another question or type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Run the chatbot simulation with Ollama rephrasing\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mchatbot_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m, in \u001b[0;36mchatbot_simulation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Rephrase the user's query using Ollama\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m rephrased_query \u001b[38;5;241m=\u001b[39m \u001b[43mrephrase_query_with_ollama\u001b[49m(user_input)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Print the rephrased query (optional, for transparency)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRephrased query: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrephrased_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rephrase_query_with_ollama' is not defined"
     ]
    }
   ],
   "source": [
    "def chatbot_simulation():\n",
    "    print(\"Hello! I'm your chatbot. Ask me anything.\")\n",
    "    \n",
    "    while True:\n",
    "        # Ask for the user's query\n",
    "        user_input = input(\"Your question: \")\n",
    "        \n",
    "        # If the user types 'exit', quit the loop\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        # Rephrase the user's query using Ollama\n",
    "        rephrased_query = rephrase_query_with_langchain(user_input)\n",
    "        \n",
    "        # Print the rephrased query (optional, for transparency)\n",
    "        print(f\"Rephrased query: '{rephrased_query}'\")\n",
    "        \n",
    "        # Query the RAG system with the rephrased query\n",
    "        answer = query_rag(rephrased_query)\n",
    "        \n",
    "        # Display the answer\n",
    "        print(f\"\\n{answer}\")\n",
    "        \n",
    "        print(\"\\nFeel free to ask another question or type 'exit' to quit.\\n\")\n",
    "\n",
    "# Run the chatbot simulation with Ollama rephrasing\n",
    "chatbot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipriv\\AppData\\Local\\Temp\\ipykernel_26780\\1473813795.py:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  rephrase_chain = LLMChain(llm=ollama_llm, prompt=rephrase_prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define a prompt template for rephrasing\n",
    "rephrase_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Rephrase the following question: '{query}'\"\n",
    ")\n",
    "\n",
    "# Set up the LLM (Ollama) integration via Langchain\n",
    "ollama_llm = Ollama(model=\"llama2\")  # Replace with the correct model name if needed\n",
    "\n",
    "# Create an LLMChain using the rephrase template and Ollama model\n",
    "rephrase_chain = LLMChain(llm=ollama_llm, prompt=rephrase_prompt)\n",
    "\n",
    "def rephrase_query_with_langchain(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Rephrase the user's query using Langchain and Ollama LLM.\n",
    "    \"\"\"\n",
    "    # Use Langchain's LLMChain to rephrase the query\n",
    "    rephrased_query = rephrase_chain.run(query)\n",
    "    return rephrased_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
